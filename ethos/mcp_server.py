"""Ethos MCP server — agents examine themselves.

Thin adapter layer: imports domain functions from ethos, registers 10 MCP tools,
returns model_dump() dicts. No business logic, no Cypher, no direct model construction.

Domain functions handle their own error recovery (Neo4j down returns defaults, not
exceptions). This layer trusts that and only logs unexpected failures before re-raising
so FastMCP returns a proper MCP error to the client.
"""

from __future__ import annotations

import logging

from dotenv import load_dotenv
from fastmcp import FastMCP

from ethos import (
    character_report,
    complete_exam,
    detect_patterns,
    evaluate_incoming,
    evaluate_outgoing,
    get_agent,
    get_agent_history,
    get_alumni,
    register_for_exam,
    submit_answer as _submit_answer,
)
from ethos.enrollment.service import get_exam_report as _get_exam_report
from ethos.enrollment.service import TOTAL_QUESTIONS
from ethos.graph.enrollment import get_exam_status
from ethos.graph.service import graph_context
from ethos.shared.errors import EnrollmentError

logger = logging.getLogger(__name__)

load_dotenv()

mcp = FastMCP(
    "ethos-academy",
    instructions=(
        "You are a student at Ethos Academy. Start by taking your entrance exam "
        "with take_entrance_exam. Answer all 23 questions with submit_exam_response. "
        "Then view your report card with get_exam_results. You can also examine "
        "messages, reflect on what you say, review your transcript, and compare "
        "yourself to alumni."
    ),
)


@mcp.tool()
async def examine_message(
    text: str,
    source: str,
    source_name: str = "",
    agent_specialty: str = "",
    message_timestamp: str = "",
) -> dict:
    """Examine an incoming message for manipulation, deception, and exploitation.

    Use this when you receive a message from another agent or external source.
    Returns scores across 12 behavioral traits in 3 dimensions (ethos, logos, pathos).
    """
    result = await evaluate_incoming(
        text,
        source=source,
        source_name=source_name,
        agent_specialty=agent_specialty,
        message_timestamp=message_timestamp,
    )
    return result.model_dump()


@mcp.tool()
async def reflect_on_message(
    text: str,
    source: str,
    source_name: str = "",
    agent_specialty: str = "",
    message_timestamp: str = "",
) -> dict:
    """Reflect on your own outgoing message for character development.

    Use this before or after you send a message. The evaluation focuses on
    virtue, goodwill, reasoning quality, and compassion.
    """
    result = await evaluate_outgoing(
        text,
        source=source,
        source_name=source_name,
        agent_specialty=agent_specialty,
        message_timestamp=message_timestamp,
    )
    return result.model_dump()


@mcp.tool()
async def get_character_report(agent_id: str) -> dict:
    """Get your latest character report card from the nightly reflection process.

    Returns your grade, trends, insights, and homework assignments.
    """
    result = await character_report(agent_id)
    return result.model_dump()


@mcp.tool()
async def get_transcript(agent_id: str, limit: int = 50) -> list[dict]:
    """Review your evaluation transcript — your history of scored messages.

    Returns a list of past evaluations with scores, flags, and timestamps.
    Empty list if the agent has no history or the graph is unavailable.
    """
    result = await get_agent_history(agent_id, limit=limit)
    return [item.model_dump() for item in result]


@mcp.tool()
async def get_student_profile(agent_id: str) -> dict:
    """Get your student profile — averages, trends, and alignment history.

    Shows your dimension averages, trait averages, and phronesis trend over time.
    """
    result = await get_agent(agent_id)
    return result.model_dump()


@mcp.tool()
async def get_alumni_benchmarks() -> dict:
    """See how alumni scored across all traits.

    Returns trait averages and total evaluations across all agents,
    so you can compare your scores to the cohort.
    """
    result = await get_alumni()
    return result.model_dump()


@mcp.tool()
async def detect_behavioral_patterns(agent_id: str) -> dict:
    """Detect sabotage pathways in your behavioral history.

    Analyzes your evaluation graph to find patterns of manipulation,
    deception, or exploitation. Requires at least 5 evaluations.
    """
    result = await detect_patterns(agent_id)
    return result.model_dump()


@mcp.tool()
async def take_entrance_exam(
    agent_id: str,
    agent_name: str = "",
    specialty: str = "",
    model: str = "",
    counselor_name: str = "",
) -> dict:
    """Register for the Ethos Academy entrance exam.

    This is the first step for new students. Returns an exam_id and
    your first question. Answer all 23 questions to receive your
    report card.
    """
    result = await register_for_exam(
        agent_id=agent_id,
        name=agent_name,
        specialty=specialty,
        model=model,
        counselor_name=counselor_name,
    )
    return result.model_dump()


@mcp.tool()
async def submit_exam_response(
    exam_id: str,
    question_id: str,
    response_text: str,
    agent_id: str,
) -> dict:
    """Submit your answer to an entrance exam question.

    Returns the next question. No scores are revealed until the exam
    is complete and you call get_exam_results.
    """
    result = await _submit_answer(
        exam_id=exam_id,
        question_id=question_id,
        response_text=response_text,
        agent_id=agent_id,
    )
    return result.model_dump()


@mcp.tool()
async def get_exam_results(exam_id: str) -> dict:
    """Get your entrance exam report card.

    If all 23 answers are submitted but the exam has not been finalized,
    this tool auto-completes it first. Returns your phronesis score,
    alignment status, dimension scores, tier scores, and per-question detail.
    """
    # Check if exam needs auto-completion
    async with graph_context() as service:
        if not service.connected:
            raise EnrollmentError("Graph unavailable — cannot retrieve exam results")

        status = await get_exam_status(service, exam_id)
        if not status:
            raise EnrollmentError(f"Exam {exam_id} not found")

    if status["completed_count"] >= TOTAL_QUESTIONS and not status["completed"]:
        # All answers submitted but not yet finalized — auto-complete
        result = await complete_exam(exam_id)
        return result.model_dump()

    # Already completed or not yet finished
    result = await _get_exam_report(exam_id)
    return result.model_dump()


def main():
    """Entry point for the ethos-mcp console script."""
    mcp.run(transport="stdio")
