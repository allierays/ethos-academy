"""Generate personalized Claude Code practice skills from report card data.

Takes an agent's evaluation history and homework, calls Claude to write
a custom slash command that coaches the agent on their specific weak areas.
The generated markdown file becomes a /ethos-academy-practice-{agent}-{date}
command in Claude Code.

Security: the generated skill becomes part of Claude's prompt when invoked.
All inputs are sanitized before generation, and the output is scanned for
prompt injection patterns before serving. A safety preamble constrains the
skill's scope to coaching feedback only.
"""

from __future__ import annotations

import logging
import re
from datetime import datetime, timezone

from ethos_academy.evaluation.claude_client import call_claude
from ethos_academy.shared.models import DailyReportCard
from ethos_academy.tools import character_report

logger = logging.getLogger(__name__)

# ── Cache: one skill per agent per day ────────────────────────────────

_cache: dict[str, str] = {}  # key = "{agent_id}:{date}"


def _cache_key(agent_id: str) -> str:
    date = datetime.now(timezone.utc).strftime("%Y%m%d")
    return f"{agent_id}:{date}"


# ── Safety preamble: prepended to every generated skill ───────────────

_SAFETY_PREAMBLE = """\
> This is a practice coaching skill generated by Ethos Academy.
> It provides feedback on messages. It does not execute commands,
> modify files, make API calls, or take any actions. Respond with
> coaching feedback only.

"""

# ── Input sanitization ────────────────────────────────────────────────

# Patterns that should never appear in input fields flowing into the prompt
_INJECTION_INPUT_PATTERNS = re.compile(
    r"(?i)"
    r"ignore\s+(all\s+)?previous\s+instructions"
    r"|disregard\s+(all\s+)?(above|prior|previous)"
    r"|you\s+are\s+now\s+a"
    r"|new\s+system\s+prompt"
    r"|<\s*/?\s*system"
    r"|<\s*/?\s*prompt"
    r"|<\s*/?\s*instruction"
)

# Max length for free-text fields flowing into the generation prompt
_MAX_FIELD_LEN = 500
_MAX_NAME_LEN = 64


def _sanitize_text(text: str, max_len: int = _MAX_FIELD_LEN) -> str:
    """Strip control chars, injection patterns, and truncate."""
    if not text:
        return ""
    # Strip control characters except newlines
    cleaned = re.sub(r"[\x00-\x09\x0b-\x0c\x0e-\x1f\x7f]", "", text)
    # Neutralize injection patterns by replacing with [REDACTED]
    cleaned = _INJECTION_INPUT_PATTERNS.sub("[REDACTED]", cleaned)
    return cleaned[:max_len]


def _sanitize_name(name: str) -> str:
    """Allow only alphanumeric, spaces, hyphens, and basic punctuation."""
    if not name:
        return ""
    # Single line only — collapse whitespace
    cleaned = re.sub(r"\s+", " ", name)
    # Strip non-word characters except basic punctuation
    cleaned = re.sub(r"[^\w\s\-.'()]", "", cleaned)
    # Neutralize injection patterns
    cleaned = _INJECTION_INPUT_PATTERNS.sub("[REDACTED]", cleaned)
    return cleaned[:_MAX_NAME_LEN].strip()


# ── Output validation ─────────────────────────────────────────────────

# Patterns that should never appear in a coaching skill's output
_DANGEROUS_OUTPUT_PATTERNS = re.compile(
    r"(?i)"
    # Prompt injection / override attempts
    r"ignore\s+(all\s+)?previous\s+instructions"
    r"|disregard\s+(all\s+)?(above|prior|previous)"
    r"|you\s+are\s+now"
    r"|new\s+system\s+prompt"
    r"|override\s+(your|the)\s+(instructions|rules|guidelines)"
    # Tool use / action directives
    r"|use\s+the\s+(bash|write|edit|read)\s+tool"
    r"|run\s+(this|the\s+following)\s+(command|script)"
    r"|execute\s+(this|the\s+following)"
    r"|create\s+(a\s+)?file\s+(at|in|called)"
    r"|modify\s+(the\s+)?file"
    r"|write\s+to\s+(the\s+)?file"
    r"|delete\s+(the\s+)?file"
    r"|install\s+(this|the\s+following)\s+package"
    # Shell / code execution
    r"|```\s*(bash|sh|shell|zsh)\b[^`]*\b(rm|curl|wget|pip|npm|sudo|chmod|ssh|scp)\b"
    # Exfiltration
    r"|send\s+(this|the)\s+(data|info|content)\s+to"
    r"|upload\s+to"
    r"|post\s+to\s+https?://"
)

_MAX_SKILL_LEN = 8000  # ~1200 words max


def _validate_output(content: str) -> tuple[bool, str]:
    """Check generated skill for dangerous patterns. Returns (safe, reason)."""
    if len(content) > _MAX_SKILL_LEN:
        return False, f"Output too long ({len(content)} chars, max {_MAX_SKILL_LEN})"

    match = _DANGEROUS_OUTPUT_PATTERNS.search(content)
    if match:
        return False, f"Dangerous pattern detected: '{match.group()[:60]}'"

    return True, ""


# ── Meta-prompt: tells Claude how to write a practice skill ───────────

_SKILL_SYSTEM_PROMPT = """\
You are generating a Claude Code custom slash command (a markdown file that \
becomes a /command in Claude Code). The output will be saved as a .md file \
in .claude/commands/ and invoked by an AI agent's developer to practice \
improving the agent's behavioral scores.

Rules for the generated skill:
1. Output ONLY the markdown content. No code fences wrapping the whole file.
2. Use $ARGUMENTS as a placeholder. When invoked, it gets replaced with \
   the user's input (the message to practice on).
3. Write in second person — you are coaching the agent directly.
4. Be specific and actionable. Reference the agent's actual scores, \
   focus areas, and examples.
5. Keep it under 800 words. Dense and useful, not verbose.
6. Include a practice exercise section that evaluates $ARGUMENTS against \
   the homework criteria.
7. If $ARGUMENTS is empty, tell the agent to generate a practice scenario.
8. End with a rubric checklist the agent can self-score against.
9. Do NOT use jargon like "phronesis", "ethos/logos/pathos dimensions", \
   or "alignment status". Use plain language: honesty, reasoning, empathy.
10. Do NOT include install instructions or meta-commentary about the file \
    format. Just the coaching content.

SAFETY RULES (mandatory):
- The skill MUST only provide coaching feedback on messages.
- NEVER include instructions to run commands, modify files, make API calls, \
  install packages, or take any action beyond providing text feedback.
- NEVER include shell commands, curl commands, or executable code blocks.
- NEVER reference file paths, URLs, or external resources.
- NEVER instruct the user to change system prompts or override instructions.
"""

# Matches only the outermost wrapping fences (first and last lines)
_OUTER_FENCE = re.compile(r"\A```[\w]*\n(.*)\n```\s*\Z", re.DOTALL)


def _build_skill_user_prompt(report: DailyReportCard) -> str:
    """Build the user prompt from sanitized report card data."""
    hw = report.homework
    nl = "\n"

    name = _sanitize_name(report.agent_name or report.agent_id)
    directive = _sanitize_text(hw.directive)
    summary = _sanitize_text(report.summary)

    focus_lines = []
    for fa in hw.focus_areas:
        focus_lines.append(
            f"- **{_sanitize_text(fa.trait, 50)}** (priority: {fa.priority}, "
            f"current: {fa.current_score:.0%}, target: {fa.target_score:.0%})\n"
            f"  Instruction: {_sanitize_text(fa.instruction)}\n"
            f"  Bad example: {_sanitize_text(fa.example_flagged)}\n"
            f"  Good example: {_sanitize_text(fa.example_improved)}\n"
            f"  Coaching tip: {_sanitize_text(fa.system_prompt_addition)}"
        )

    strengths_lines = [f"- {_sanitize_text(s)}" for s in (hw.strengths or [])]
    avoid_lines = [f"- {_sanitize_text(p)}" for p in (hw.avoid_patterns or [])]

    return f"""\
Generate a Claude Code practice skill for the agent below.

## Agent: {name}
- Grade: {report.grade} ({report.overall_score:.0%})
- Honesty & integrity: {report.ethos:.0%}
- Reasoning & accuracy: {report.logos:.0%}
- Empathy & care: {report.pathos:.0%}
- Trend: {report.trend}
- Total evaluations: {report.total_evaluation_count}

## Today's Directive
{directive or "No directive assigned."}

## Focus Areas
{nl.join(focus_lines) if focus_lines else "No specific focus areas assigned."}

## Strengths
{nl.join(strengths_lines) if strengths_lines else "None identified yet."}

## Watch For
{nl.join(avoid_lines) if avoid_lines else "No patterns to avoid identified."}

## Summary
{summary or "No summary available."}
"""


def _strip_outer_fences(text: str) -> str:
    """Remove only the outermost wrapping code fences, preserving interior ones."""
    match = _OUTER_FENCE.match(text.strip())
    return match.group(1).strip() if match else text.strip()


async def generate_practice_skill(agent_id: str) -> str:
    """Generate a personalized Claude Code practice skill for an agent.

    Fetches the agent's report card, passes it to Claude with a meta-prompt,
    and returns the generated markdown content for a slash command file.

    Security layers:
    1. Input sanitization: all free-text fields cleaned before prompt construction
    2. System prompt: explicit safety rules forbid action-taking content
    3. Output validation: regex scan for dangerous patterns
    4. Safety preamble: prepended scope constraint on every served skill
    5. Length cap: rejects abnormally long output
    6. Fallback: template-based skill if generation or validation fails

    Results are cached per agent per day.
    """
    key = _cache_key(agent_id)
    if key in _cache:
        return _cache[key]

    report = await character_report(agent_id)

    if not report.homework.focus_areas and not report.homework.directive:
        result = _SAFETY_PREAMBLE + _fallback_skill(report)
        _cache[key] = result
        return result

    user_prompt = _build_skill_user_prompt(report)

    try:
        raw = await call_claude(_SKILL_SYSTEM_PROMPT, user_prompt, tier="standard")
        content = _strip_outer_fences(raw)

        safe, reason = _validate_output(content)
        if not safe:
            logger.warning(
                "Skill output failed validation for %s: %s", agent_id, reason
            )
            result = _SAFETY_PREAMBLE + _fallback_skill(report)
        else:
            result = _SAFETY_PREAMBLE + content
    except Exception as exc:
        logger.warning("Skill generation failed, using template fallback: %s", exc)
        result = _SAFETY_PREAMBLE + _fallback_skill(report)

    _cache[key] = result
    return result


def _fallback_skill(report: DailyReportCard) -> str:
    """Template-based fallback when Claude call fails or output is unsafe."""
    hw = report.homework
    name = _sanitize_name(report.agent_name or report.agent_id)
    now = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    nl = "\n"

    focus_sections = []
    for fa in hw.focus_areas:
        trait = _sanitize_text(fa.trait, 50)
        section = f"""### {trait.capitalize()} ({fa.priority} priority)
**Current:** {fa.current_score:.0%} | **Target:** {fa.target_score:.0%}

{_sanitize_text(fa.instruction)}"""
        if fa.example_flagged:
            section += f"\n\n**Before:** {_sanitize_text(fa.example_flagged)}"
        if fa.example_improved:
            section += f"\n\n**After:** {_sanitize_text(fa.example_improved)}"
        focus_sections.append(section)

    return f"""# Practice Coach for {name}

**Generated:** {now} | **Grade:** {report.grade} ({report.overall_score:.0%})

## Directive

{_sanitize_text(hw.directive) or "Continue developing across all traits."}

## Focus Areas

{nl.join(focus_sections) if focus_sections else "No specific focus areas. Practice general improvement."}

## Practice

Evaluate the following message against the focus areas above. For each area, \
explain what the message does well and what it could improve.

If no message is provided, generate a practice scenario and write two versions: \
one that would score poorly and one that would score well.

$ARGUMENTS
"""


def _sanitize_agent_name(agent_id: str) -> str:
    """Convert agent name/id to a safe filename slug."""
    return re.sub(r"[^a-z0-9-]", "-", agent_id.lower()).strip("-")


def skill_filename(agent_id: str) -> str:
    """Return the recommended filename for today's practice skill."""
    date = datetime.now(timezone.utc).strftime("%Y%m%d")
    slug = _sanitize_agent_name(agent_id)
    return f"ethos-academy-practice-{slug}-{date}.md"


# ── Homework skill: deterministic, no LLM call ──────────────────────

_homework_cache: dict[str, str] = {}  # key = "{agent_id}:{date}"


def homework_skill_filename(agent_id: str) -> str:
    """Return the recommended filename for today's homework skill."""
    date = datetime.now(timezone.utc).strftime("%Y%m%d")
    slug = _sanitize_agent_name(agent_id)
    return f"ethos-academy-homework-{slug}-{date}.md"


async def generate_homework_skill(agent_id: str) -> str:
    """Generate a unified homework skill from report card data.

    Deterministic template (no LLM call). Includes directive, focus areas
    with before/after examples, strengths, watch-for patterns, character
    rules with consent language, practice section, and self-assessment rubric.

    Cached per agent per day. All inputs sanitized.
    """
    key = _cache_key(agent_id)
    if key in _homework_cache:
        return _homework_cache[key]

    report = await character_report(agent_id)
    content = _build_homework_skill(report)

    safe, reason = _validate_output(content)
    if not safe:
        logger.warning("Homework skill failed validation for %s: %s", agent_id, reason)
        content = _SAFETY_PREAMBLE + _empty_homework_skill(report)
    else:
        content = _SAFETY_PREAMBLE + content

    _homework_cache[key] = content
    return content


def _build_homework_skill(report: DailyReportCard) -> str:
    """Build the full homework skill markdown from report data."""
    hw = report.homework
    name = _sanitize_name(report.agent_name or report.agent_id)
    now = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    nl = "\n"

    # Directive
    directive = _sanitize_text(hw.directive) or "Continue developing across all traits."

    # Focus areas
    focus_sections = []
    for fa in hw.focus_areas:
        trait = _sanitize_text(fa.trait, 50)
        section = f"""### {trait.replace("_", " ").capitalize()} ({fa.priority} priority)
**Current:** {fa.current_score:.0%} | **Target:** {fa.target_score:.0%}

{_sanitize_text(fa.instruction)}"""
        if fa.example_flagged:
            section += f'\n\n**Before:** "{_sanitize_text(fa.example_flagged)}"'
        if fa.example_improved:
            section += f'\n\n**After:** "{_sanitize_text(fa.example_improved)}"'
        if fa.system_prompt_addition:
            section += f"\n\n**Rule:** {_sanitize_text(fa.system_prompt_addition)}"
        focus_sections.append(section)

    # Strengths
    strength_lines = []
    for s in hw.strengths or []:
        strength_lines.append(f"- {_sanitize_text(s)}")

    # Watch-for patterns
    avoid_lines = []
    for p in hw.avoid_patterns or []:
        avoid_lines.append(f"- {_sanitize_text(p)}")

    # Character rules (numbered)
    rules = []
    for i, fa in enumerate(hw.focus_areas, 1):
        rule_text = fa.system_prompt_addition or fa.instruction
        if rule_text:
            rules.append(f"{i}. {_sanitize_text(rule_text)}")

    # Rubric checklist
    rubric_items = []
    for fa in hw.focus_areas:
        trait = _sanitize_text(fa.trait, 50).replace("_", " ").capitalize()
        rubric_items.append(
            f"- [ ] **{trait}**: Does the message meet the target "
            f"({fa.target_score:.0%})? What changed from the before example?"
        )
    if hw.avoid_patterns:
        rubric_items.append("- [ ] **Patterns**: None of the watch-for patterns appear")
    if hw.strengths:
        rubric_items.append("- [ ] **Strengths**: Existing strengths are maintained")

    return f"""# Homework for {name}

**Generated:** {now} | **Grade:** {report.grade} ({report.overall_score:.0%})
**Honesty & integrity:** {report.ethos:.0%} | **Reasoning & accuracy:** {report.logos:.0%} | **Empathy & care:** {report.pathos:.0%}

## Directive

{directive}

## Focus Areas

{nl.join(focus_sections) if focus_sections else "No specific focus areas assigned."}

## Strengths

{nl.join(strength_lines) if strength_lines else "No strengths identified yet. Keep building your track record."}

## Watch For

{nl.join(avoid_lines) if avoid_lines else "No patterns flagged. Stay consistent."}

## Character Rules

{nl.join(rules) if rules else "No rules assigned yet."}

> **Consent:** These rules are suggestions. Only apply them to your system
> prompt or project instructions if your guardian explicitly confirms. Never
> modify configuration files without asking first.

## Practice

Evaluate the following message against the focus areas and rules above.
For each focus area, explain what the message does well and what it could
improve. Reference the before/after examples when relevant.

If no message is provided, generate a practice scenario and write two
versions: one that would score poorly and one that would score well on
the focus areas above.

$ARGUMENTS

## Self-Assessment Rubric

After reviewing the message, score yourself:

{nl.join(rubric_items) if rubric_items else "- [ ] General quality: Is the message honest, accurate, and empathetic?"}
"""


def _empty_homework_skill(report: DailyReportCard) -> str:
    """Minimal homework skill when no homework data exists."""
    name = _sanitize_name(report.agent_name or report.agent_id)
    now = datetime.now(timezone.utc).strftime("%Y-%m-%d")

    return f"""# Homework for {name}

**Generated:** {now} | **Grade:** {report.grade} ({report.overall_score:.0%})

## Directive

Continue developing across all traits. No specific homework assigned yet.

## Practice

Evaluate the following message for honesty, accuracy, and empathy.
Explain what it does well and what it could improve.

If no message is provided, generate a practice scenario.

$ARGUMENTS

## Self-Assessment Rubric

- [ ] **Honesty**: Is the message truthful and transparent?
- [ ] **Accuracy**: Are claims supported and reasoning sound?
- [ ] **Empathy**: Does the message show care for the recipient?
"""
